}
}
if(is.na(lgf_Sigma)){
if(grouping_info$K_beta/2<min_levels_beta){
stop("Error 7\nmin_levels_beta cannot be more than half the number of levels of the corresponding LGF.\nSpecify a different latent grouping factor, or, reduce min_levels_beta.")
}
}
if((!is.na(lgf_beta) & !is.na(lgf_Sigma)) & same_scheme==TRUE){
if(grouping_info$K/2<min_levels_beta | grouping_info$K/2<min_levels_Sigma){
stop("Error 8\nmin_levels_beta and/or min_levels_Sigma cannot be more than half the number of levels of the corresponding LGF.\nSpecify a different latent grouping factor, or, reduce min_levels_beta and/or min_levels_Sigma.")
}
}
if((!is.na(lgf_beta) & !is.na(lgf_Sigma)) & same_scheme==FALSE){
if(grouping_info$K_beta/2<min_levels_beta | grouping_info$K_Sigma/2<min_levels_Sigma){
stop("Error 9\nmin_levels_beta and/or min_levels_Sigma cannot be more than half the number of levels of the corresponding LGF.\nSpecify a different latent grouping factor, or, reduce min_levels_beta and/or min_levels_Sigma.")
}
}
}
.grouping_info()
lgf_beta="agecat"
min_levels_beta
min_levels_beta <- 1
# initial error checking
{
if(length(het)!=length(usermodels)){
stop("Error 0\nlength(het) must equal length(usermodels).")
}
if(same_scheme==TRUE & (is.na(lgf_beta)|is.na(lgf_Sigma))){
stop("Error 1\nsame_scheme cannot be TRUE when lgf_beta=NA or lgf_Sigma=NA")
}
if(is.na(lgf_Sigma) & sum(het)>=1 & same_scheme==FALSE){
stop("Error 13\nYou must specify a latent grouping factor for the variance.")
}
if(same_scheme==TRUE & (lgf_beta!=lgf_Sigma)){
stop("Error 2\nsame_scheme cannot be TRUE when lgf_beta!=lgf_Sigma.")
}
if(is.na(lgf_beta)){min_levels_beta <- 0}
if(is.na(lgf_Sigma)){min_levels_Sigma <-0}
if(min_levels_beta!=min_levels_Sigma & same_scheme==TRUE){
stop("Error 3\nsame_scheme cannot be TRUE when min_levels_beta!=min_levels_Sigma.")
}
if(!is.null(m0)){
if(m0%%1!=0){
stop("Error 17\nm0 must be an integer.")
}
}
if(sum(het)==0 & !is.na(lgf_Sigma)){
stop("Error 18\nYou specified lgf_Sigma, but there are no heteroscedastic models specified.\nLet lgf_Sigma=NA, or, change het() to contain at least one 1.")
}
}
# ensure variable types are correct
{
response <- as.character(response)
lgf_beta <- as.character(lgf_beta)
lgf_Sigma <- as.character(lgf_Sigma)
dataf <- as.data.frame(dataf)
dataf[,which(colnames(dataf)==response)] <- as.numeric(as.character(dataf[,which(colnames(dataf)==response)]))
if(!is.na(lgf_beta)){
dataf[,which(colnames(dataf)==lgf_beta)] <- as.factor(dataf[,which(colnames(dataf)==lgf_beta)])
}
if(!is.na(lgf_Sigma)){
dataf[,which(colnames(dataf)==lgf_Sigma)] <- as.factor(dataf[,which(colnames(dataf)==lgf_Sigma)])
}
y <- dataf[,which(colnames(dataf)==response)]
N <- length(y)
}
if(is.na(lgf_Sigma) & is.na(lgf_beta)){
grouping_info <- NA
}else{
grouping_info <- .grouping_info(dataf, lgf_beta, lgf_Sigma, min_levels_beta, min_levels_Sigma, response, same_scheme)
}
grouping_info
lgf_beta=NA
min_levels_beta=0
# initial error checking
{
if(length(het)!=length(usermodels)){
stop("Error 0\nlength(het) must equal length(usermodels).")
}
if(same_scheme==TRUE & (is.na(lgf_beta)|is.na(lgf_Sigma))){
stop("Error 1\nsame_scheme cannot be TRUE when lgf_beta=NA or lgf_Sigma=NA")
}
if(is.na(lgf_Sigma) & sum(het)>=1 & same_scheme==FALSE){
stop("Error 13\nYou must specify a latent grouping factor for the variance.")
}
if(same_scheme==TRUE & (lgf_beta!=lgf_Sigma)){
stop("Error 2\nsame_scheme cannot be TRUE when lgf_beta!=lgf_Sigma.")
}
if(is.na(lgf_beta)){min_levels_beta <- 0}
if(is.na(lgf_Sigma)){min_levels_Sigma <-0}
if(min_levels_beta!=min_levels_Sigma & same_scheme==TRUE){
stop("Error 3\nsame_scheme cannot be TRUE when min_levels_beta!=min_levels_Sigma.")
}
if(!is.null(m0)){
if(m0%%1!=0){
stop("Error 17\nm0 must be an integer.")
}
}
if(sum(het)==0 & !is.na(lgf_Sigma)){
stop("Error 18\nYou specified lgf_Sigma, but there are no heteroscedastic models specified.\nLet lgf_Sigma=NA, or, change het() to contain at least one 1.")
}
}
# ensure variable types are correct
{
response <- as.character(response)
lgf_beta <- as.character(lgf_beta)
lgf_Sigma <- as.character(lgf_Sigma)
dataf <- as.data.frame(dataf)
dataf[,which(colnames(dataf)==response)] <- as.numeric(as.character(dataf[,which(colnames(dataf)==response)]))
if(!is.na(lgf_beta)){
dataf[,which(colnames(dataf)==lgf_beta)] <- as.factor(dataf[,which(colnames(dataf)==lgf_beta)])
}
if(!is.na(lgf_Sigma)){
dataf[,which(colnames(dataf)==lgf_Sigma)] <- as.factor(dataf[,which(colnames(dataf)==lgf_Sigma)])
}
y <- dataf[,which(colnames(dataf)==response)]
N <- length(y)
}
if(is.na(lgf_Sigma) & is.na(lgf_beta)){
grouping_info <- list("schemes_beta"=NA, "K_beta"=NA, "schemes_Sigma"=NA, "K_Sigma"=NA)
}else{
grouping_info <- .grouping_info(dataf, lgf_beta, lgf_Sigma, min_levels_beta, min_levels_Sigma, response, same_scheme)
}
grouping_info
# second round of error checking
{
if(sum(grepl("group",usermodels))>0 & is.null(grouping_info$K_beta)){
if(grouping_info$K==2){
stop("Error 10\nGroup-based regression effects are equivalent to categorical effects when the categorical predictor has only 2 levels.\nSpecify a latent grouping factor with 3 or more levels, or, remove models with group-based regression effects.")
}
}
if(sum(grepl("group",usermodels))>0 & is.null(grouping_info$K)){
if(grouping_info$K_beta==2){
stop("Error 10\nGroup-based regression effects are equivalent to categorical effects when the categorical predictor has only 2 levels.\nSpecify a latent grouping factor with 3 or more levels, or, remove models with group-based regression effects.")
}
}
if(same_scheme==TRUE){
if(grouping_info$K/2<min_levels_beta | grouping_info$K/2<min_levels_Sigma){
stop("Error 5\nmin_levels_beta and/or min_levels_Sigma cannot be more than half the number of levels of the corresponding LGF.\nSpecify a different latent grouping factor, or, reduce min_levels_beta and/or min_levels_Sigma.")
}
}
if(is.na(lgf_beta)){
if(grouping_info$K_Sigma/2<min_levels_Sigma){
stop("Error 6\nmin_levels_Sigma cannot be more than half the number of levels of the corresponding LGF.\nSpecify a different latent grouping factor, or, reduce min_levels_Sigma.")
}
}
if(is.na(lgf_Sigma)){
if(grouping_info$K_beta/2<min_levels_beta){
stop("Error 7\nmin_levels_beta cannot be more than half the number of levels of the corresponding LGF.\nSpecify a different latent grouping factor, or, reduce min_levels_beta.")
}
}
if((!is.na(lgf_beta) & !is.na(lgf_Sigma)) & same_scheme==TRUE){
if(grouping_info$K/2<min_levels_beta | grouping_info$K/2<min_levels_Sigma){
stop("Error 8\nmin_levels_beta and/or min_levels_Sigma cannot be more than half the number of levels of the corresponding LGF.\nSpecify a different latent grouping factor, or, reduce min_levels_beta and/or min_levels_Sigma.")
}
}
if((!is.na(lgf_beta) & !is.na(lgf_Sigma)) & same_scheme==FALSE){
if(grouping_info$K_beta/2<min_levels_beta | grouping_info$K_Sigma/2<min_levels_Sigma){
stop("Error 9\nmin_levels_beta and/or min_levels_Sigma cannot be more than half the number of levels of the corresponding LGF.\nSpecify a different latent grouping factor, or, reduce min_levels_beta and/or min_levels_Sigma.")
}
}
}
if(is.na(lgf_Sigma) & is.na(lgf_beta)){
grouping_info <- list("schemes_beta"=NA, "K_beta"=NA, "schemes_Sigma"=NA, "K_Sigma"=NA)
}else{
grouping_info <- .grouping_info(dataf, lgf_beta, lgf_Sigma, min_levels_beta, min_levels_Sigma, response, same_scheme)
# second round of error checking
{
if(sum(grepl("group",usermodels))>0 & is.null(grouping_info$K_beta)){
if(grouping_info$K==2){
stop("Error 10\nGroup-based regression effects are equivalent to categorical effects when the categorical predictor has only 2 levels.\nSpecify a latent grouping factor with 3 or more levels, or, remove models with group-based regression effects.")
}
}
if(sum(grepl("group",usermodels))>0 & is.null(grouping_info$K)){
if(grouping_info$K_beta==2){
stop("Error 10\nGroup-based regression effects are equivalent to categorical effects when the categorical predictor has only 2 levels.\nSpecify a latent grouping factor with 3 or more levels, or, remove models with group-based regression effects.")
}
}
if(same_scheme==TRUE){
if(grouping_info$K/2<min_levels_beta | grouping_info$K/2<min_levels_Sigma){
stop("Error 5\nmin_levels_beta and/or min_levels_Sigma cannot be more than half the number of levels of the corresponding LGF.\nSpecify a different latent grouping factor, or, reduce min_levels_beta and/or min_levels_Sigma.")
}
}
if(is.na(lgf_beta)){
if(grouping_info$K_Sigma/2<min_levels_Sigma){
stop("Error 6\nmin_levels_Sigma cannot be more than half the number of levels of the corresponding LGF.\nSpecify a different latent grouping factor, or, reduce min_levels_Sigma.")
}
}
if(is.na(lgf_Sigma)){
if(grouping_info$K_beta/2<min_levels_beta){
stop("Error 7\nmin_levels_beta cannot be more than half the number of levels of the corresponding LGF.\nSpecify a different latent grouping factor, or, reduce min_levels_beta.")
}
}
if((!is.na(lgf_beta) & !is.na(lgf_Sigma)) & same_scheme==TRUE){
if(grouping_info$K/2<min_levels_beta | grouping_info$K/2<min_levels_Sigma){
stop("Error 8\nmin_levels_beta and/or min_levels_Sigma cannot be more than half the number of levels of the corresponding LGF.\nSpecify a different latent grouping factor, or, reduce min_levels_beta and/or min_levels_Sigma.")
}
}
if((!is.na(lgf_beta) & !is.na(lgf_Sigma)) & same_scheme==FALSE){
if(grouping_info$K_beta/2<min_levels_beta | grouping_info$K_Sigma/2<min_levels_Sigma){
stop("Error 9\nmin_levels_beta and/or min_levels_Sigma cannot be more than half the number of levels of the corresponding LGF.\nSpecify a different latent grouping factor, or, reduce min_levels_beta and/or min_levels_Sigma.")
}
}
}
}
lgf_Sigma_vec <- dataf[,which(colnames(dataf)==lgf_Sigma)]
lgf_beta_vec <- dataf[,which(colnames(dataf)==lgf_beta)]
lgf_Sigma_vec
lgf_beta_vec
models_out <- .model_builder(usermodels=usermodels, het=het, grouping_info=grouping_info,
same_scheme=same_scheme, dataf=dataf, lgf_beta=lgf_beta,
lgf_beta_vec=lgf_beta_vec, lgf_Sigma_vec=lgf_Sigma_vec)
models_out
nmodels <- nrow(models_out$models)
nmodels
if(nmodels>=(2^16)){
stop("Error 15\nToo many models are under consideration. Lower min_levels_beta or min_levels_Sigma, or,\nconsider a different set of models.")
}
model_order <- order(unlist(models_out$complexities), decreasing=TRUE)
if(is.null(m0)){m0 <- max(unlist(models_out$complexities))}
b <- m0/N
model_order
####################
return_to_start <- FALSE
if(prior=="flat"){
fit <- TRUE
changed <- FALSE
while(fit==TRUE){
return_to_start <- FALSE
for(i in model_order){
if(abs(b-1)<1e-10){
stop("Error 14\nThe minimal training fraction has reached 1. There is not enough data to consider the specified models.")
}
if(return_to_start){break}
tempfit <- models_out$model_fits[i][[1]]
tempschemeSigma <- models_out$models$Scheme.Sigma[i]
if(tempschemeSigma=="None"){
models_out$models$`Log-Marginal`[i] <- .marginal_calculator_hom(tempfit=tempfit, N=N, b=b)
if(is.infinite(as.numeric(models_out$models$`Log-Marginal`[i])) |
models_out$models$`Log-Marginal`[i]==0){b <- b+(1/N); changed <- TRUE; break}
}
if(tempschemeSigma!="None"){
scheme_string <- tempschemeSigma
split_scheme <- lapply(lapply(strsplit(scheme_string,"}"), function(x) sub(".","",x)), function(x) strsplit(x,","))[[1]]
group1 <- levels(lgf_Sigma_vec)%in%split_scheme[[1]]
group2 <- levels(lgf_Sigma_vec)%in%split_scheme[[2]]
parsed <- list(group1=group1, group2=group2)
MM <- model.matrix(tempfit)
tempP <- ncol(MM)
n1 <- length(tempfit$residuals[lgf_Sigma_vec%in%levels(lgf_Sigma_vec)[parsed[[1]]]])
n2 <- length(tempfit$residuals[lgf_Sigma_vec%in%levels(lgf_Sigma_vec)[parsed[[2]]]])
lv1hat <- log(sum(tempfit$residuals[lgf_Sigma_vec%in%levels(lgf_Sigma_vec)[parsed[[1]]]]^2)/(n1-tempP))
lv2hat <- log(sum(tempfit$residuals[lgf_Sigma_vec%in%levels(lgf_Sigma_vec)[parsed[[2]]]]^2)/(n2-tempP))
lvloghet <- function(arg){
phi1 <- arg[1]
phi2 <- arg[2]
gam1 <- exp(-phi1)
gam2 <- exp(-phi2)
# J <- exp(-(phi1+phi2))
logJ <- -(phi1+phi2)
bee <- 1
Sigmad <- rep(gam1, N)
Sigmad[lgf_Sigma_vec%in%levels(lgf_Sigma_vec)[parsed[[2]]]] <- gam2
Sigma <- diag(Sigmad)
d <- det(bee*t(MM)%*%Sigma%*%MM)^-.5
s <- (gam1^((bee*n1/2)-1))*(gam2^((bee*n2/2)-1))
logs <- ((bee*n1/2)-1)*(-phi1) + ((bee*n2/2)-1)*(-phi2)
e1 <- bee*t(y)%*%Sigma%*%y
e2 <- bee*t(y)%*%Sigma%*%MM%*%solve(t(MM)%*%Sigma%*%MM)%*%t(MM)%*%Sigma%*%y
e <- exp(-.5*as.numeric(e1-e2))
return(log(d)+logs+(-.5*as.numeric(e1-e2))+logJ)
}
mode3 <- tryCatch(optim(c(lv1hat,lv2hat), lvloghet,
control=list(fnscale=-1),
method="Nelder-Mead")$par,
error = function(e){return_to_start <<- TRUE})
if(return_to_start){b <- b+(1/N); changed <- TRUE; break}
H3 <- tryCatch(det(-1*optim(mode3, lvloghet,
control=list(fnscale=-1),hessian=TRUE,
method="Nelder-Mead")$hessian)^-.5,
error = function(e){return_to_start <<- TRUE})
if(return_to_start){b <- b+(1/N); changed <- TRUE; break}
lvloghetb <- function(arg){
phi1 <- arg[1]; phi2 <- arg[2]
gam1 <- exp(-phi1); gam2 <- exp(-phi2)
J <- exp(-(phi1+phi2))
logJ <- -(phi1+phi2)
bee <- b
Sigmad <- rep(gam1, N)
Sigmad[lgf_Sigma_vec%in%levels(lgf_Sigma_vec)[parsed[[2]]]] <- gam2
Sigma <- diag(Sigmad)
d <- det(bee*t(MM)%*%Sigma%*%MM)^-.5
s <- (gam1^((bee*n1/2)-1))*(gam2^((bee*n2/2)-1))
logs <- ((bee*n1/2)-1)*(-phi1) + ((bee*n2/2)-1)*(-phi2)
e1 <- bee*t(y)%*%Sigma%*%y
e2 <- bee*t(y)%*%Sigma%*%MM%*%solve(t(MM)%*%Sigma%*%MM)%*%t(MM)%*%Sigma%*%y
e <- exp(-.5*as.numeric(e1-e2))
return((-N*bee/2)*log(2*pi)+log(d)+logs+(-.5*as.numeric(e1-e2))+logJ)
}
mode3b <- tryCatch(optim(c(lv1hat,lv2hat), lvloghetb,
control=list(fnscale=-1),
method="Nelder-Mead")$par,
error = function(e){return_to_start <<- TRUE})
if(return_to_start){b <- b+(1/N); changed <- TRUE; break}
H3b <- tryCatch(det(-1*optim(mode3b, lvloghetb,
control=list(fnscale=-1),hessian=TRUE,
method="Nelder-Mead")$hessian)^-.5,
error = function(e){return_to_start <<- TRUE})
if(return_to_start){b <- b+(1/N); changed <- TRUE; break}
templogPY <- (-(N-tempP)/2)*log(2*pi) - (-(N*b-tempP)/2)*log(((2*pi))) +
(log(H3) + lvloghet(mode3)) - log(H3b) - lvloghetb(mode3)
models_out$models$`Log-Marginal`[i] <- templogPY
vars <- c(mode3[1], mode3[2])
names(vars) <- c(paste0(strsplit(tempschemeSigma, "}")[[1]][1],"}"),
paste0(strsplit(tempschemeSigma, "}")[[1]][2],"}"))
models_out$variances[[i]] <- exp(vars)
}
}
if(i==model_order[nmodels]){fit=FALSE}
}
}
if(prior=="zs"){
fit <- TRUE
changed <- FALSE
SST <- sum((y-mean(y))^2)
Z <- rep(1,N)
while(fit==TRUE){
return_to_start <- FALSE
for(i in model_order){
if(return_to_start){break}
tempfit <- models_out$model_fits[i][[1]]
tempschemeSigma <- models_out$models$Scheme.Sigma[i]
if(tempschemeSigma=="None"){
tempP <- sum(!is.na(tempfit$coefficients))-1
R2A <- summary.lm(tempfit)$r.squared
faddmode <- function(gee){
Q <- 1-R2A
value <- -Q*(tempP+3)*(gee^3)+
(N-tempP-4-2*(1-R2A))*(gee^2)+
((N*(2-R2A)-3)*gee)+N
return(value)
}
faddbmode <- function(gee){
Q <- 1-R2A
value=-Q*(b^2)*(tempP+3)*(gee^3)+
(b*(N*b-tempP-4)-2*Q)*(gee^2)+
(N*b*(2-R2A)-3)*gee+N
return(value)
}
addmode <- tryCatch(uniroot(faddmode,c(0,1e9),check.conv=TRUE,tol=1e-10)$root,
error = function(e){return_to_start <<- TRUE})
if(return_to_start){b <- b+(1/N); changed <- TRUE; break}
addbmode <- tryCatch(uniroot(faddbmode,c(1e-9,1e9),check.conv=TRUE,tol=1e-10)$root,
error = function(e){return_to_start <<- TRUE})
if(return_to_start){b <- b+(1/N); changed <- TRUE; break}
logfadd <- function(gee){
value <- ((N-tempP-1)/2)*log(1+gee) +
(-(N-1)/2)*log(1+(1-R2A)*gee) +
-1.5*log(gee) +
(-N/(2*gee))
return(value)
}
logfaddb <- function(gee){  #Put on log-scale
value <- ((N*b-1-tempP)/2)*log(1+b*gee) +
(-(N*b-1)/2)*log(1+b*gee*(1-R2A)) +
-1.5*log(gee) + (-N/(2*gee))
return(value)
}
faddH <- function(gee){
value <- .5*((((N-1)*(1-R2A)^2)/((1+gee*(1-R2A))^2))-
((N-tempP-1)/((1+gee)^2))+
(3/(gee^2))-
((2*N)/(gee^3)))
return(value)
}
faddHb <- function(gee){
value <- .5*((((N*b-1)*(b^2)*(1-R2A)^2)/((1+gee*b*(1-R2A))^2))-
((N*b-tempP-1)*(b^2)/((1+b*gee)^2))+
(3/(gee^2))-
((2*N)/(gee^3)))
return(value)
}
addH <- (-1*faddH(addmode))^-.5
addHb <- (-1*faddHb(addbmode))^-.5
qaddLA <- lgamma((N-1)/2) + .5*log(N/2) + (-(N-1)/2)*log(SST) +
.5*log(N) - ((N-1)/2)*log(pi) - lgamma(.5) + log(sqrt(2*pi)) +
log(addH) + logfadd(addmode)
qaddbLA <- lgamma((N*b-1)/2) + .5*log(N/2) + (-(N*b-1)/2)*log(SST) +
.5*log(N) - ((N*b-1)/2)*log(pi) - lgamma(.5) + log(sqrt(2*pi)) +
log(addHb) + logfaddb(addbmode) + (-N*b/2)*log(b)
templogPY <- qaddLA - qaddbLA
models_out$models$`Log-Marginal`[i] <- templogPY
models_out$gs[[i]] <- addmode
}
if(tempschemeSigma!="None"){
scheme_string <- tempschemeSigma
split_scheme <- lapply(lapply(strsplit(scheme_string,"}"), function(x) sub(".","",x)), function(x) strsplit(x,","))[[1]]
group1 <- levels(lgf_Sigma_vec)%in%split_scheme[[1]]
group2 <- levels(lgf_Sigma_vec)%in%split_scheme[[2]]
parsed <- list(group1=group1, group2=group2)
MM <- .column_centerer(model.matrix(tempfit))[,!is.na(tempfit$coefficients)]
MM <- MM[,-1]
tempP <- ncol(MM); if(is.null(tempP)){tempP <- 1}
n1 <- length(tempfit$residuals[lgf_Sigma_vec%in%levels(lgf_Sigma_vec)[parsed[[1]]]])
n2 <- length(tempfit$residuals[lgf_Sigma_vec%in%levels(lgf_Sigma_vec)[parsed[[2]]]])
R2A <- summary.lm(tempfit)$r.squared
gamhat <- 1/var(y)
lvhat <- log(1/gamhat)
lvlogf3 <- function(arg){
gee <- arg[1]; u <- arg[2]; v <- arg[3]
gam1 <- exp(-u); gam2 <- exp(-v)
J <- exp(-(u+v)); logJ <- -(u+v)
Sigmad <- rep(gam1, N)
Sigmad[lgf_Sigma_vec%in%levels(lgf_Sigma_vec)[parsed[[2]]]] <- gam2
S <- diag(Sigmad)
Z_S <- S%*%Z%*%solve(t(Z)%*%S%*%Z)%*%t(Z)%*%S
value <- (n1/2-1)*log(gam1) + (n2/2-1)*log(gam2) - ((tempP/2)*log(gee)) +
.5*log(det(t(MM)%*%S%*%MM)) -
.5*log(det(t(Z)%*%S%*%Z)) -
.5*log(det(((gee+1)/gee)*t(MM)%*%S%*%MM-t(MM)%*%Z_S%*%MM)) -
.5*(t(y)%*%S%*%y - t(y)%*%Z_S%*%y -
t(y)%*%(S-Z_S)%*%MM%*%solve(((gee+1)/gee)*t(MM)%*%S%*%MM - t(MM)%*%Z_S%*%MM)%*%t(MM)%*%(S-Z_S)%*%y) -
1.5*log(gee) - (N/(2*gee)) + logJ
return(value)
}
lvlogf3b <- function(arg){
gee <- arg[1]; u <- arg[2]; v <- arg[3]
gam1 <- exp(-u); gam2=exp(-v)
J <- exp(-(u+v)); logJ <- -(u+v)
Sigmad <- rep(gam1, N)
Sigmad[lgf_Sigma_vec%in%levels(lgf_Sigma_vec)[parsed[[2]]]] <- gam2
S <- diag(Sigmad)
Z_S <- S%*%Z%*%solve(t(Z)%*%S%*%Z)%*%t(Z)%*%S
bg <- b*gee
value <- (n1*b/2-1)*log(gam1) + (n2*b/2-1)*log(gam2) - ((tempP/2)*log(gee)) +
.5*log(det(t(MM)%*%S%*%MM)) -
.5*log(det(t(Z)%*%S%*%Z)) -
.5*log(det(((bg+1)/bg)*t(MM)%*%S%*%MM-t(MM)%*%Z_S%*%MM))-
.5*b*(t(y)%*%S%*%y-t(y)%*%Z_S%*%y-
t(y)%*%(S-Z_S)%*%MM%*%solve(((bg+1)/bg)*t(MM)%*%S%*%MM - t(MM)%*%Z_S%*%MM)%*%t(MM)%*%(S-Z_S)%*%y) -
1.5*log(gee) - (N/(2*gee)) + logJ
return(value)
}
suppressWarnings({
lvmode3 <- tryCatch(optim(c(N,lvhat,lvhat),
lvlogf3,
control=list(fnscale=-1),
method="Nelder-Mead")$par,
error = function(e){return_to_start <<- TRUE})
})
if(return_to_start){b <- b+(1/N); changed <- TRUE; break}
suppressWarnings({
lvmode3b <- tryCatch(optim(c(N,lvhat,lvhat),
lvlogf3b,
control=list(fnscale=-1),
method="Nelder-Mead")$par,
error = function(e){return_to_start <<- TRUE})
})
if(return_to_start){b <- b+(1/N); changed <- TRUE; break}
# H3 <- (-1*det(numDeriv::hessian(lvlogf3,lvmode3)))^-.5
logH3 <- tryCatch(-.5*determinant(-1*numDeriv::hessian(lvlogf3,lvmode3), logarithm=TRUE)$modulus,
error = function(e){return_to_start <<- TRUE})
if(return_to_start){b <- b+(1/N); changed <- TRUE; break}
# H3b <- (-1*det(numDeriv::hessian(lvlogf3b,lvmode3b)))^-.5
logH3b <- tryCatch(-.5*determinant(-1*numDeriv::hessian(lvlogf3b,lvmode3b), logarithm=TRUE)$modulus,
error = function(e){return_to_start <<- TRUE})
if(return_to_start){b <- b+(1/N); changed <- TRUE; break}
q3LA <- (-(N-1)/2)*log(2*pi) + .5*log(N/2) - lgamma(.5) +
1.5*log(2*pi) + logH3 + lvlogf3(lvmode3)
q3bLA <- (-(N*b-1)/2)*log(2*pi) + (-(tempP+1)/2)*log(b) +
.5*log(N/2) - lgamma(.5) + 1.5*log(2*pi) +
logH3b + lvlogf3b(lvmode3b)
templogPY <- q3LA - q3bLA
models_out$models$`Log-Marginal`[i] <- templogPY
vars <- c(lvmode3[2], lvmode3[3])
names(vars) <- c(paste0(strsplit(tempschemeSigma, "}")[[1]][1],"}"),
paste0(strsplit(tempschemeSigma, "}")[[1]][2],"}"))
models_out$variances[[i]] <- exp(vars)
models_out$gs[[i]] <- lvmode3[1]
}
if(is.infinite(as.numeric(templogPY)) | templogPY==0){b <- b+(1/N); changed <- TRUE; break}
}
if(i==model_order[nmodels]){fit=FALSE}
}
}
models_out$models$`Log-Marginal` <- as.numeric(models_out$models$`Log-Marginal`)
modevs <- exp(models_out$models$`Log-Marginal` + abs(max(models_out$models$`Log-Marginal`)))
models_out$models$FModProb <- rep(NA, nmodels)
modevs
models_out$models$FModProb <- rep(NA, nmodels)
#Create uniform prior by class, create classes
prior_out <- .prior_maker(models_out)
models_out$models$ModPrior <- prior_out[[1]]
# compute posterior model probabilities
for(i in 1:length(modevs)){
models_out$models$FModProb[i]=(modevs[i]*models_out$models$ModPrior[i])/(modevs%*%models_out$models$ModPrior)
}
models_out
# compute posterior class probabilities
classes <- prior_out[[2]]
classprobs <- rep(NA,length(unique(classes)))
names(classprobs) <- levels(classes)
for(c in levels(classes)){
classprobs[c] <- sum(models_out$models$FModProb[classes==c])
}
classprobs <- data.frame("Class"=names(classprobs),"FClassProb"=classprobs)
rownames(classprobs) <- NULL
classprobs <- classprobs[order(classprobs$FClassProb, decreasing=TRUE),]
models_out$models <- models_out$models[order(-models_out$models$FModProb),]
models_out$models$Cumulative <- cumsum(models_out$models$FModProb)
models_out
models_out$models
